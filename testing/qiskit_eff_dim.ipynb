{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "from qiskit.primitives import StatevectorSampler as Sampler, StatevectorEstimator as Estimator\n",
    "\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "from qiskit_machine_learning.neural_networks import EffectiveDimension\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "\n",
    "from models.qiskit_models import serial, strongly_parallel, all_to_all_crz, all_to_all_rzz, strongly_crz, strongly_rzz\n",
    "\n",
    "\n",
    "algorithm_globals.random_seed = 42\n",
    "sampler = Sampler()\n",
    "estimator = Estimator()"
   ],
   "id": "66f312645c755e06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "def serial_mixed(degree, )",
   "id": "c091eb5fec83f22e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qc_str_ser, weights, _, _ = serial(5, 2, 1)\n",
    "qc_str_ser.draw(output='mpl')"
   ],
   "id": "e0229853031261ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "qc = QNNCircuit(\n",
    "    feature_map=ZZFeatureMap(feature_dimension=4, entanglement='full', reps=2),\n",
    "    ansatz=RealAmplitudes(4, entanglement='full', reps=2, flatten=True),\n",
    ")\n",
    "enc = ZZFeatureMap(feature_dimension=4, entanglement='full', reps=2)\n",
    "enc.decompose().draw(output='mpl')\n",
    "# qc.draw(output=\"mpl\", style=\"clifford\")"
   ],
   "id": "8bf9f5926b0be576"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def parity(x):\n",
    "    return \"{:b}\".format(x).count(\"1\") % 2"
   ],
   "id": "92e83ac49c9c38f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "serial_models = [serial(degree=10, trainable_blocks=l, scaling=1) for l in range(1, 10)]\n",
    "strongly_entangling_parallel_models = [strongly_parallel(n_qubits=10, trainable_layers=l, scaling=1) for l in range(1, 8)]\n",
    "strongly_entangling_crz_models = [strongly_crz(n_qubits=10, trainable_layers=l, scaling=1) for l in range(1, 10)]\n",
    "strongly_entangling_rzz_models = [strongly_rzz(n_qubits=10, trainable_layers=l, scaling=1) for l in range(1, 10)]\n",
    "all_to_all_crz_models = [all_to_all_crz(n_qubits=10, trainable_layers=l, scaling=1) for l in range(1, 5)]\n",
    "all_to_all_rzz_models = [all_to_all_rzz(n_qubits=10, trainable_layers=l, scaling=1) for l in range(1, 8)]\n",
    "\n",
    "varying_models = [serial_models, strongly_entangling_parallel_models, strongly_entangling_crz_models, strongly_entangling_rzz_models, all_to_all_crz_models, all_to_all_rzz_models]\n",
    "n = [5000, 8000, 10000, 40000, 60000, 100000, 150000, 200000, 500000, 1000000]"
   ],
   "id": "f6644f4434b5943d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "eff_dim_of_varying_models = []\n",
    "\n",
    "for models in varying_models:\n",
    "    for model in models:\n",
    "        qc, weights, feature, name = model\n",
    "        if models is strongly_entangling_parallel_models:\n",
    "            weight_params = [param for layer in weights['W'] for vec in layer for param in vec]\n",
    "            final_params = []\n",
    "        elif models is serial_models:\n",
    "            weight_params = [param for vec in weights['W'] for param in vec]\n",
    "            final_params = []\n",
    "        else:\n",
    "            weight_params = [param for layer in weights['W'] for vec in layer for param in vec]\n",
    "            final_params = [param for vec in weights['final'] for param in vec]\n",
    "        input_data = [feature]\n",
    "        qnn = SamplerQNN(\n",
    "            circuit=qc,\n",
    "            input_params=input_data,\n",
    "            weight_params=weight_params + final_params,\n",
    "            interpret=parity,\n",
    "            output_shape=2,\n",
    "            sparse=False,\n",
    "            sampler=sampler\n",
    "        )\n",
    "        d = qnn.num_weights\n",
    "        input_samples = algorithm_globals.random.normal(0, 1, size=(10, qnn.num_inputs))\n",
    "        weight_samples = algorithm_globals.random.uniform(0, 1, size=(10, qnn.num_weights))\n",
    "        global_ed = EffectiveDimension(qnn, weight_samples, input_samples)\n",
    "        global_eff_dim = global_ed.get_effective_dimension(dataset_size=n)\n",
    "        eff_dim_of_varying_models.append((global_eff_dim, d, name))\n",
    "        print(\"Stats of {}: number of weights = {}, effective dimension = {}\".format(name, d, global_eff_dim))\n",
    "\n",
    "    with open(\"eff_dims/eff_dim_of_varying_models_10qubits.pkl\", \"wb\") as f:\n",
    "        pickle.dump(eff_dim_of_varying_models, f)\n"
   ],
   "id": "e70655fb2feebb7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"eff_dims/eff_dim_of_varying_models_10qubits.pkl\", \"wb\") as f:\n",
    "    pickle.dump(eff_dim_of_varying_models, f)"
   ],
   "id": "b2e8abe7cc02f0fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "group_colors = {\n",
    "    \"serial\": \"tab:blue\",\n",
    "    \"parallel\": \"tab:orange\",\n",
    "    \"strongly_crz\": \"tab:green\",\n",
    "    \"strongly_rzz\": \"tab:red\",\n",
    "    \"all_to_all_crz\": \"tab:purple\",\n",
    "    \"all_to_all_rzz\": \"tab:brown\"\n",
    "}\n",
    "\n",
    "# Map group to models\n",
    "model_groups = {\n",
    "    \"serial\": serial_models,\n",
    "    \"parallel\": strongly_entangling_parallel_models,\n",
    "    \"strongly_crz\": strongly_entangling_crz_models,\n",
    "    \"strongly_rzz\": strongly_entangling_rzz_models,\n",
    "    \"all_to_all_crz\": all_to_all_crz_models,\n",
    "    \"all_to_all_rzz\": all_to_all_rzz_models\n",
    "}\n",
    "\n",
    "# Create a reverse map from model name to group (assumes unique names!)\n",
    "model_to_group = {}\n",
    "for group_name, models in model_groups.items():\n",
    "    for model in models:\n",
    "        _, _, _, name = model\n",
    "        model_to_group[name] = group_name\n",
    "\n",
    "# Sort results\n",
    "eff_dim_of_varying_models.sort(key=lambda x: max(np.array(x[0]) / x[1]), reverse=True)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "n_grid = np.array(n)\n",
    "\n",
    "# Keep track of which group has been added to legend\n",
    "group_labels_plotted = set()\n",
    "\n",
    "for ed, d, name in eff_dim_of_varying_models:\n",
    "    norm_ed = np.array(ed) / d\n",
    "    d_grid = np.full_like(n_grid, d)\n",
    "\n",
    "    group = model_to_group.get(name, \"unknown\")\n",
    "    color = group_colors.get(group, \"gray\")\n",
    "\n",
    "    # Add label only once per group\n",
    "    label = group if group not in group_labels_plotted else None\n",
    "    group_labels_plotted.add(group)\n",
    "\n",
    "    ax.plot(n_grid, d_grid, ed, label=label, color=color)\n",
    "\n",
    "ax.set_xlabel(\"Number of data (n)\")\n",
    "ax.set_ylabel(\"Number of parameters (d)\")\n",
    "ax.set_zlabel(\"Normalized Global Effective Dimension\")\n",
    "ax.set_title(\"Effective Dimension vs Model Size and Dataset Size\")\n",
    "ax.legend(title=\"Model Groups\", loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"plots/eff_dim_plot_10qubits.png\", dpi=300, bbox_inches='tight')"
   ],
   "id": "d086d5ed6b78c2d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "table_data = {}\n",
    "\n",
    "for dims, d, name in eff_dim_of_varying_models:\n",
    "    mean_dim = np.mean(dims)\n",
    "    if name not in table_data:\n",
    "        table_data[name] = {}\n",
    "    table_data[name][d] = mean_dim\n",
    "# for dims, d, name in eff_dim_of_models:\n",
    "#     mean_dim = np.mean(dims)\n",
    "#     if name not in table_data:\n",
    "#         table_data[name] = {}\n",
    "#     table_data[name][d] = mean_dim\n",
    "\n",
    "# mean_dim = np.mean(global_eff_dim_1)\n",
    "# table_data[name1] = {}\n",
    "# table_data[name1][d1] = mean_dim\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(table_data, orient='index')\n",
    "df.columns.name = 'Number of parameters (d)'\n",
    "df.index.name = 'Model'\n",
    "\n",
    "df = df[sorted(df.columns, reverse=False)]\n",
    "\n",
    "display(df.style.format(\"{:.2f}\", na_rep='–'))"
   ],
   "id": "8eef832524dee8b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "table_data = {}\n",
    "\n",
    "for dims, d, name in eff_dim_of_varying_models:\n",
    "    mean_dim = np.mean(dims)\n",
    "    if name not in table_data:\n",
    "        table_data[name] = {}\n",
    "    table_data[name][d] = mean_dim\n",
    "# for dims, d, name in eff_dim_of_models:\n",
    "#     mean_dim = np.mean(dims)\n",
    "#     if name not in table_data:\n",
    "#         table_data[name] = {}\n",
    "#     table_data[name][d] = mean_dim\n",
    "\n",
    "# mean_dim = np.mean(global_eff_dim_1)\n",
    "# table_data[name1] = {}\n",
    "# table_data[name1][d1] = mean_dim\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(table_data, orient='index')\n",
    "df.columns.name = 'Number of parameters (d)'\n",
    "df.index.name = 'Model'\n",
    "\n",
    "df = df[sorted(df.columns, reverse=False)]\n",
    "\n",
    "display(df.style.format(\"{:.2f}\", na_rep='–'))"
   ],
   "id": "2a536f35a7904d20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"eff_dims/eff_dim_of_varying_models3.pkl\", \"rb\") as f:\n",
    "    eff_dim_of_varying_models = pickle.load(f)"
   ],
   "id": "d8906f0667623390"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "models = [strongly_parallel(n_qubits=5, trainable_layers=l, scaling=1) for l in range(1, 4)]\n",
    "\n",
    "n = [5000, 8000, 10000, 40000, 60000, 100000, 150000, 200000, 500000, 1000000]\n",
    "eff_dim_of_models = []\n",
    "\n",
    "for model in models:\n",
    "    qc, weights, feature, name = model\n",
    "    weight_params = [param for layer in weights['W'] for vec in layer for param in vec]\n",
    "    # final_params = [param for vec in weights['final'] for param in vec]\n",
    "    input_data = [feature]\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=input_data,\n",
    "        weight_params=weight_params, # + final_params,\n",
    "        interpret=parity,\n",
    "        output_shape=2,\n",
    "        sparse=False,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    d = qnn.num_weights\n",
    "    input_samples = algorithm_globals.random.normal(0, 1, size=(10, qnn.num_inputs))\n",
    "    weight_samples = algorithm_globals.random.uniform(0, 1, size=(10, qnn.num_weights))\n",
    "    global_ed = EffectiveDimension(qnn, weight_samples, input_samples)\n",
    "    global_eff_dim = global_ed.get_effective_dimension(dataset_size=n)\n",
    "    eff_dim_of_models.append((global_eff_dim, d, name))\n",
    "    print(\"Stats of {}: number of weights = {}, effective dimension = {}\".format(name, d, global_eff_dim))"
   ],
   "id": "6fc172bddcfbad07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for ed in eff_dim_of_models:\n",
    "    plt.plot(n, np.array(ed[0]) / ed[1], label=f\"{ed[2]} {ed[1]}\")\n",
    "\n",
    "plt.xlabel(\"Number of data\")\n",
    "plt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "172d6dfcdb31d6f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "eff_dim_of_models.sort(key=lambda x: max(np.array(x[0]) / x[1]), reverse=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "n_grid = np.array(n)\n",
    "\n",
    "for ed, d, name in eff_dim_of_models:\n",
    "    norm_ed = np.array(ed) / d\n",
    "    d_grid = np.full_like(n_grid, d)\n",
    "    ax.plot(n_grid, d_grid, norm_ed, label=f\"{name} {d}\")\n",
    "\n",
    "ax.set_xlabel(\"Number of data (n)\")\n",
    "ax.set_ylabel(\"Number of parameters (d)\")\n",
    "ax.set_zlabel(\"Normalized Global Effective Dimension\")\n",
    "ax.set_title(\"Effective Dimension vs Model Size and Dataset Size\")\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"plots/eff_dim_para.png\", dpi=300, bbox_inches='tight')"
   ],
   "id": "1634946d427a8c44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# circuit, weights, feature\n",
    "# qc1, weights_dict1, feature_param1, name1 = serial(degree=5, scaling=1)\n",
    "\n",
    "# Flatten parameters\n",
    "# weight_params1 = [param for layer in weights_dict1['W'] for vec in layer for param in vec]\n",
    "# final_params1 = [param for vec in weights_dict1['final'] for param in vec]\n",
    "# weight_params1 = [param for vec in weights_dict1[\"W\"] for param in vec]\n",
    "# input_params1 = [feature_param1]\n",
    "\n",
    "qnn1 = SamplerQNN(\n",
    "    circuit=qc,\n",
    "    # input_params=input_params1,\n",
    "    # weight_params=weight_params1,\n",
    "    interpret=parity,\n",
    "    output_shape=2,  # +1 or -1 → 2-class classification\n",
    "    sparse=False,\n",
    "    sampler=sampler\n",
    ")\n",
    "\n",
    "d1 = qnn1.num_weights\n",
    "\n",
    "input_samples1 = algorithm_globals.random.normal(0, 1, size=(10, qnn1.num_inputs))\n",
    "weight_samples1 = algorithm_globals.random.uniform(0, 1, size=(10, qnn1.num_weights))\n",
    "\n",
    "global_ed1 = EffectiveDimension(qnn=qnn1, weight_samples=weight_samples1, input_samples=input_samples1)\n",
    "\n",
    "n = [5000, 8000, 10000, 40000, 60000, 100000, 150000, 200000, 500000, 1000000]\n",
    "global_eff_dim_1 = global_ed1.get_effective_dimension(dataset_size=n)\n",
    "print(\"Number of weights in {}: {}, norm_ed = {}\".format(\"Abas\", d1, global_eff_dim_1))\n",
    "# plot the normalized effective dimension for the model\n",
    "plt.plot(n, np.array(global_eff_dim_1) / d1, label=\"Abas\")\n",
    "plt.xlabel(\"Number of data\")\n",
    "plt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "acaf8afa4731f4fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9971d14ec0176f21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
