{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "import numpy as np\n",
    "# from pennylane import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from models.pennylane_models import serial, strongly_parallel, all_to_all_crz, all_to_all_rzz, strongly_crz, strongly_rzz, basic_mixed, one_to_all_mixed, all_to_one_mixed\n",
    "\n",
    "seed=12\n",
    "def keygenerator(seed=seed):\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    while True:\n",
    "        key, subkey = jax.random.split(key)\n",
    "        yield subkey"
   ],
   "id": "5da0bb2fc9d2d04d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "coeffs = [\n",
    "    (1.29 + 1.13j),  # c_1\n",
    "    (0.43 + 0.89j),  # c_2\n",
    "    (1.97 + 1.03j),  # c_3\n",
    "    (0.17 + 0.59j),  # c_4\n",
    "    (1.71 + 1.41j),  # c_5\n",
    "    (0.61 + 0.37j),  # c_6\n",
    "    (1.19 + 1.67j),  # c_7\n",
    "    (0.73 + 1.61j),  # c_8\n",
    "    (0.23 + 0.47j),  # c_9\n",
    "    (1.83 + 0.83j),  # c_10\n",
    "]\n",
    "\n",
    "c0 = 0.0\n",
    "scaling = 1\n",
    "\n",
    "def target_function(x):\n",
    "    res = c0\n",
    "    for idx, c in enumerate(coeffs):\n",
    "        exponent = scaling * (idx + 1) * x * 1j\n",
    "        conj_c = jnp.conjugate(c)\n",
    "        res += c * jnp.exp(exponent) + conj_c * jnp.exp(-exponent)\n",
    "    return jnp.real(res)\n",
    "\n",
    "def minmax_scaler(y):\n",
    "    # Scale y to [0, 1]\n",
    "    y_min = jnp.min(y)\n",
    "    y_max = jnp.max(y)\n",
    "    y_scaled = (y - y_min) / (y_max - y_min)\n",
    "    return y_scaled"
   ],
   "id": "e517bd214396c846"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_raw = jnp.linspace(-12, 12, 200)\n",
    "x = minmax_scaler(x_raw) * 2 * jnp.pi\n",
    "target_y = jax.vmap(target_function)(x)\n",
    "\n",
    "target_y_scaled = minmax_scaler(target_y) * 2 - 1\n",
    "\n",
    "# plt.plot(x, target_y, c=\"black\")\n",
    "plt.scatter(x, target_y_scaled, facecolor=\"white\", edgecolor=\"black\")\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.show()"
   ],
   "id": "6cab713eef168e63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "keys = keygenerator()\n",
    "\n",
    "serial_models = [serial(x, 10, l, 1, next(keys)) for l in range(1, 10)]\n",
    "strongly_entangling_parallel_models = [strongly_parallel(x, n_qubits=10, trainable_layers=l, scaling=1, random_key=next(keys)) for l in range(1, 8)]\n",
    "basic_entangling_mixed_models = [basic_mixed(x, n_qubits=10, trainable_layers=l, scaling=1, random_key1=next(keys), random_key2=next(keys)) for l in range(1, 8)]\n",
    "one_to_all_mixed_models = [one_to_all_mixed(x, n_qubits=10, trainable_layers=l, scaling=1, random_key1=next(keys), random_key2=next(keys)) for l in range(1, 8)]\n",
    "all_to_one_mixed_models = [all_to_one_mixed(x, n_qubits=10, trainable_layers=l, scaling=1, random_key1=next(keys), random_key2=next(keys)) for l in range(1, 8)]\n",
    "strongly_entangling_crz_models = [strongly_crz(x, n_qubits=10, trainable_layers=l, scaling=1, random_key1=next(keys), random_key2=next(keys)) for l in range(1, 10)]\n",
    "strongly_entangling_rzz_models = [strongly_rzz(x, n_qubits=10, trainable_layers=l, scaling=1, random_key1=next(keys), random_key2=next(keys)) for l in range(1, 10)]\n",
    "all_to_all_crz_models = [all_to_all_crz(x, n_qubits=10, trainable_layers=l, scaling=1, random_key1=next(keys), random_key2=next(keys)) for l in range(1, 5)]\n",
    "all_to_all_rzz_models = [all_to_all_rzz(x, n_qubits=10, trainable_layers=l, scaling=1, random_key1=next(keys), random_key2=next(keys)) for l in range(1, 8)]\n",
    "\n",
    "varying_models = [strongly_entangling_crz_models]\n",
    "\n",
    "# qm, weights, name = all_to_all_crz_models[0]\n",
    "# print(qml.draw(qm, level=\"device\")(weights, x))"
   ],
   "id": "b9ce348b6b0705b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def square_loss(targets, predictions):\n",
    "    return 0.5 * jnp.mean((targets - predictions) ** 2)\n",
    "\n",
    "def cost(weights, model, x, y):\n",
    "    predictions = jax.vmap(lambda x_: model(weights, x_))(x)\n",
    "    # predictions = model(weights, x)\n",
    "    return square_loss(y, predictions)\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_resid = jnp.sum((y_true - y_pred) ** 2)\n",
    "    ss_total = jnp.sum((y_true - jnp.mean(y_true)) ** 2)\n",
    "    return 1 - ss_resid / ss_total\n",
    "\n",
    "\n",
    "class GradientLogger:\n",
    "    def __init__(self):\n",
    "        self.log = {\n",
    "            \"step\": [],\n",
    "            \"loss\": [],\n",
    "            \"grad_mean\": [],\n",
    "            \"grad_std\": [],\n",
    "            \"grad_min\": [],\n",
    "            \"grad_max\": [],\n",
    "        }\n",
    "\n",
    "    def get_gradients(self, weights, model, x, target_y):\n",
    "        cost_fn = lambda w: cost(w, model, x, target_y)\n",
    "        grads = jax.grad(cost_fn)(weights)\n",
    "\n",
    "        # Flatten all gradient arrays into a single vector\n",
    "        flat_grads = jnp.concatenate([jnp.ravel(g) for g in jax.tree_util.tree_leaves(grads)])\n",
    "\n",
    "        return flat_grads\n",
    "\n",
    "    def update(self, step, loss_val, flat_grads):\n",
    "        self.log[\"step\"].append(step)\n",
    "        self.log[\"loss\"].append(loss_val)\n",
    "        self.log[\"grad_mean\"].append(jnp.mean(flat_grads))\n",
    "        self.log[\"grad_std\"].append(jnp.std(flat_grads))\n",
    "        self.log[\"grad_min\"].append(jnp.min(flat_grads))\n",
    "        self.log[\"grad_max\"].append(jnp.max(flat_grads))\n",
    "\n",
    "    def get_logs(self):\n",
    "        return self.log"
   ],
   "id": "f8c1dd3cf19bdf25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions_r2scores_models = []\n",
    "gradient_logger = []\n",
    "costs = []\n",
    "\n",
    "for models in varying_models:\n",
    "    layer = 0\n",
    "    plt.plot(x, target_y_scaled, c=\"black\")\n",
    "    plt.scatter(x, target_y_scaled, facecolor=\"white\", edgecolor=\"black\")\n",
    "\n",
    "    for model in models:\n",
    "        qm, weights, name = model\n",
    "        opt = optax.adam(0.01)\n",
    "        opt_state = opt.init(weights)\n",
    "        layer += 1\n",
    "        if models in (serial_models, strongly_entangling_parallel_models):\n",
    "            d = weights.size\n",
    "        else:\n",
    "            d = weights['W'].size + weights['final'].size\n",
    "\n",
    "        @jax.jit\n",
    "        def update_step(weights, opt_state, x_batch, y_batch):\n",
    "            loss_fn = lambda w: cost(w, qm, x_batch, y_batch)\n",
    "            loss, grads = jax.value_and_grad(loss_fn)(weights)\n",
    "            # loss, grads = jax.value_and_grad(cost)(qm, weights, x_batch, y_batch)\n",
    "            updates, opt_state = opt.update(grads, opt_state)\n",
    "            weights = optax.apply_updates(weights, updates)\n",
    "            return weights, opt_state, loss\n",
    "\n",
    "        max_steps = 5000\n",
    "        batch_size = 25\n",
    "        cst = [cost(weights, qm, x, target_y)]  # initial cost\n",
    "        logger = GradientLogger()\n",
    "\n",
    "        for step in range(max_steps):\n",
    "\n",
    "            batch_index = jax.random.choice(next(keys), len(x), (batch_size,), replace=False)\n",
    "\n",
    "            x_batch = x[batch_index]\n",
    "            y_batch = target_y_scaled[batch_index]\n",
    "\n",
    "            weights, opt_state, _ = update_step(weights, opt_state, x_batch, y_batch)\n",
    "\n",
    "            c = cost(weights, qm, x, target_y_scaled)\n",
    "            cst.append(c)\n",
    "\n",
    "            grads = logger.get_gradients(weights, qm, x, target_y_scaled)\n",
    "            logger.update(step, c, grads)\n",
    "\n",
    "            if (step + 1) % 1000 == 0:\n",
    "                print(\"Cost at step {0:3} for {1} params: {2}\".format(step + 1, d, c))\n",
    "\n",
    "        costs.append((cst, name, d))\n",
    "        gradient_logger.append((logger.get_logs(), name, d))\n",
    "\n",
    "        predictions = jax.vmap(lambda x_: qm(weights, x_))(x)\n",
    "        r2 = r2_score(target_y_scaled, predictions)\n",
    "        predictions_r2scores_models.append((predictions, r2, name, d))\n",
    "\n",
    "        plt.plot(x, predictions, label=f\"{name}_{d}: R² = {r2:.4f}\")\n",
    "\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f\"plots/model_performances_{name}.png\")\n",
    "\n",
    "with open(f\"preds_and_r2/predictions_r2scores_models_10qubits_str_crz{seed}\", \"wb\") as f:\n",
    "    pickle.dump(predictions_r2scores_models, f)\n",
    "with open(f\"preds_and_r2/gradients_10qubits_str_crz{seed}\", \"wb\") as f:\n",
    "    pickle.dump(gradient_logger, f)\n",
    "with open(f\"preds_and_r2/costs_10qubits_str_crz{seed}\", \"wb\") as f:\n",
    "    pickle.dump(costs, f)"
   ],
   "id": "d426ea55024d52a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions_by_model = defaultdict(list)\n",
    "r2s_by_model = defaultdict(list)\n",
    "\n",
    "for preds, r2, name, d in predictions_r2scores_models:\n",
    "    predictions_by_model[(name, d)].append(preds)\n",
    "    r2s_by_model[(name, d)].append(r2)\n",
    "\n",
    "for (name, d), preds_list in predictions_by_model.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, target_y, color='black', label='Target function')\n",
    "\n",
    "    preds_array = np.array(preds_list)  # shape: (n_seeds, n_points)\n",
    "    mean_preds = preds_array.mean(axis=0)\n",
    "    std_preds = preds_array.std(axis=0)\n",
    "\n",
    "    # Compute R² stats\n",
    "    r2s = r2s_by_model[(name, d)]\n",
    "    mean_r2 = np.mean(r2s)\n",
    "    std_r2 = np.std(r2s)\n",
    "\n",
    "    # Plot mean prediction\n",
    "    plt.plot(x, mean_preds, label=f\"{name}_{d}: R² = {mean_r2:.4f} ± {std_r2:.4f}\")\n",
    "    plt.fill_between(x, mean_preds - std_preds, mean_preds + std_preds, alpha=0.2)\n",
    "\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.title(f\"Model Predictions Averaged Over Seeds — {name} (d={d})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "f70fcbac88c8b6c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "r2_by_d = defaultdict(list)\n",
    "\n",
    "for _, r2, name, d in predictions_r2scores_models:\n",
    "    r2_by_d[d].append(r2)\n",
    "\n",
    "sorted_ds = sorted(r2_by_d.keys())\n",
    "\n",
    "# Transpose the data so rows = seeds\n",
    "df = pd.DataFrame(list(zip(*[r2_by_d[d] for d in sorted_ds])), columns=sorted_ds)\n",
    "df.columns.name = \"Number of parameters (d)\"\n",
    "df.index.name = \"Seed\"\n",
    "\n",
    "display(df.style.format(\"{:.4f}\", na_rep='–'))"
   ],
   "id": "7c8d2a21badc951e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Group costs by model\n",
    "costs_by_model = defaultdict(list)\n",
    "\n",
    "for cost_list, name, d in costs:\n",
    "    costs_by_model[(name, d)].append(cost_list)\n",
    "\n",
    "# Plot\n",
    "for (name, d), all_costs in costs_by_model.items():\n",
    "    # Pad all cost lists to the same length if needed\n",
    "    max_len = max(len(c) for c in all_costs)\n",
    "    padded = np.array([c + [np.nan] * (max_len - len(c)) for c in all_costs])\n",
    "\n",
    "    mean_cost = np.nanmean(padded, axis=0)\n",
    "    std_cost = np.nanstd(padded, axis=0)\n",
    "\n",
    "    steps = np.arange(len(mean_cost))\n",
    "\n",
    "    plt.plot(steps, mean_cost, label=f\"{name} ({d} params)\")\n",
    "    plt.fill_between(steps, mean_cost - std_cost, mean_cost + std_cost, alpha=0.2)\n",
    "\n",
    "    plt.xlabel(\"Training steps\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.title(\"Average Training Cost over Seeds\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "ced0557cd2767c94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "table_data = {}\n",
    "\n",
    "for _, r2, name, d in predictions_r2scores_models:\n",
    "    if name not in table_data:\n",
    "        table_data[name] = {}\n",
    "    table_data[name][d] = r2\n",
    "\n",
    "df = pd.DataFrame.from_dict(table_data, orient='index')\n",
    "df.columns.name = 'Number of parameters (d)'\n",
    "df.index.name = 'Model'\n",
    "\n",
    "df = df[sorted(df.columns, reverse=False)]\n",
    "\n",
    "display(df.style.format(\"{:.4f}\", na_rep='–'))"
   ],
   "id": "c8c0c09777943fd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(x, target_y_scaled, c=\"black\")\n",
    "# plt.scatter(x, target_y_scaled, facecolor=\"white\", edgecolor=\"black\")\n",
    "\n",
    "for i in range(len(predictions_r2scores_models)):\n",
    "    predictions, r2, name, d = predictions_r2scores_models[i]\n",
    "    if d == 790:\n",
    "        plt.plot(x, predictions, label=f\"{name}_{d}: R² = {r2:.4f}\")\n",
    "\n",
    "plt.ylim(-1, 1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(predictions, r2, name, d)"
   ],
   "id": "c32ee3e907cf417a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"preds_and_r2/predictions_r2scores_models_10qubits_dummy_ata_rzz\", \"rb\") as f:\n",
    "    predictions_r2scores_models = pickle.load(f)\n",
    "with open(\"preds_and_r2/gradients_10qubits_dummy_ata_rzz\", \"rb\") as f:\n",
    "    gradient_loggers = pickle.load(f)\n",
    "with open(\"preds_and_r2/costs_10qubits_dummy_ata_rzz\", \"rb\") as f:\n",
    "    costs = pickle.load(f)"
   ],
   "id": "3c02f9fd63c76cc7"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
